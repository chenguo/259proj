\section{Project Implementation}
Our simulator provides a cycle accurate behavioral model of a standard circular re-order buffer.  At the outset of the project, the standard re-order buffer we intended to implement was a non-circular RAM-based re-order buffer.  However, after feedback from the course instructor and students it was decided that a circular buffer is more widely held as being the 'standard' buffer type and would serve as an ideal underlying model for power optimizations.  Thus, we implement and compare the standard circular re-order buffer to circular re-order buffers with the following optimizations: 1) Distributed (Cluster based) ROB, 2) Dynamically Sized ROB, 3) Reduced Output Port ROB (Retention Latch). The following sections outline each of the above model implementations as well as input instruction generation and power results tabulation.
\subsection{Instruction Generation}

\begin{table*}
\centering
\begin{tabular}{|c|c|c|c|} \hline
Instruction Type&Cycle Count&Instruction Type&Cycle Count\\ \hline
\texttt{LOAD}&20&\texttt{STORE}&20\\ \hline
\texttt{ADD}&1&\texttt{FADD}&3\\ \hline
\texttt{SUB}&1&\texttt{FSUB}&3\\ \hline
\texttt{MULT}&3&\texttt{FMULT}&5\\ \hline
\texttt{DIV}&18&\texttt{FDIV}&6\\ \hline\end{tabular}
\caption{Modeled instruction types and their corresponding completion cycle counts.}
\label{tab:instypetable}
\end{table*}

We model the input to our simulator as a stream of integer and floatpoint instructions.  The instructions are represented at the bit-level and model MIPS instructions as closely as possible.  Each instruction consists of 1) Instruction type, 2) Source and destination registers 3) a PC.  Table ~\ref{tab:instypetable} indicates the types of instructions modeled.  Each instruction type also has a predetermined cycle execution time designating the number of cycles that must elapse between instruction issue and the completion of the instruction.  As modeling functional units goes beyond the scope of this simulator, instructions are flagged as complete after the listed number of cycles has elapsed.  The actual cycle counts are the same as those modeled in MIT's Graphite many-core processor simulator\cite{graphite}, with the exception of LOAD and STORE.  The cycle counts corresponding to LOAD and STORE instructions are estimated as a predetermined 20 cycles each.  This is simply an estimation as the actual cycle count is heavily dependent on cache architecture and benchmark specific cache behavior.  Since both of these topics are beyond the scope of the simulator, we estimate the completion time of LOAD and STORE instructions as a set value substantially longer than the other more accurate instruction types.

Registers are generated in bit representation as 4 bits each totaling 12 bits for the s1, s2 and d registers in each instruction. Currently, our representation of instructions make no distinction between zero, 1, and 2 operand instructions.  All instructions regardless of type feature two operands.  This feature is supported by the fact that a memory hierarchy and functional units are not simulated by our system and as such immediate values have no direct use.  Further, every instruction features a d register regardless of type.  Because our simulator features operand forwarding from the ROB, it is necessary for the generation of registers to keep track of past destination registers to use as dependent operands in future instructions.  This history buffer is implemented as a rotating bit register from which prior destination registers can be indexed.

Each instruction also features a program counter associated with the instruction.  While this is clearly a simplification of a real system, it serves the purposes of our simulation as a uniquely identifiable tag by which to differentiate instructions.  In both a real system and our simulator, a statically set 32 bit value is used to represent this PC/tag.  As such, the specific values contained in the PC/tag will yield accurate transition results (nonexistent) and is thus are irrelevant.  Simply starting the PC of the first instruction in the stream at 0 and incrementing by 4 each instruction guarantees uniqueness among PCs and serves the purposes of an instruction tag.

The aforementioned instruction fields have multiple modes of generation.  Our simulator synthetically generates an instruction input trace based on a prescribed instruction profile.  The instruction profile features: 1) a percent rate of occurrence for each instruction type, 2) a rate corresponding to the interdependence of registers between instructions, and 3) an overall instruction count.

The instruction generator is currently capable of generating four distinct instruction streams corresponding to different instruction workloads.  The first instruction stream is marked as the default instruction stream.  It features equal percentages of each type of instruction as well as a 10\% register dependence rate.  This register dependence rate was selected arbitrarily to act as a starting point for modeling data dependencies between instructions.

The remaining three instruction streams are modeled after SPEC-FP benchmarks \cite{rupnow}.  The benchmarks were chosen to represent three major modes of operation:  floating point heavy execution, integer heavy execution, and mixed type execution.  For a floating point heavy execution, 173.applu was selected and modeled.  173.applu models parabolic/elliptical partial differential equations and features almost exclusively floating point operations as well as a large number of memory operations making it useful as both a floating point benchmark as well as a long running memory intensive benchmark.  191.fma3d is used to model integer heavy execution.  It models finite-element crash simulation and features very few floating point operations and substantially fewer memory operations than 173.applu making it an ideal light-weight integer workload.  Finally, 183.equake is used to represent the average workload.  It models seismic wave propagation and features both integer and floating point operations as well as moderate memory usage.  As such it acts as a more representative general workload than the original default workload.  Each of the SPEC-FP benchmarks feature a 6{\char'045} register forwarding frequency as is reported by \cite{kucuk}.

\begin{table*}
\centering
\begin{tabular}{|c|c|c|c|c|} \hline
ins{\char'137}profile&default{\char'137}profile&173{\char'056}applu&191{\char'056}fma3d&183{\char'056}equake\\ \hline
loadProc&0.10&0.32&0.12&0.37\\ \hline
storeProc&0.10&0.12&0.24&0.06\\ \hline
addProc&0.10&0.01&0.15&0.08\\ \hline
subProc&0.10&0.01&0.15&0.08\\ \hline
multProc&0.10&0.01&0.15&0.08\\ \hline
divProc&0.10&0.01&0.15&0.08\\ \hline
faddProc&0.10&0.13&0.01&0.07\\ \hline
fsubProc&0.10&0.13&0.01&0.06\\ \hline
fmultProc&0.10&0.13&0.01&0.06\\ \hline
fdivProc&0.10&0.13&0.01&0.06\\ \hline
forwardingRate&0.10&0.06&0.06&0.06\\ \hline
instCount&100000&100000&100000&100000\\ \hline\end{tabular}
\caption{Benchmark Instruction Profiles showing percent rate of occurrence of each instruction type.}
\label{tab:insprofile}
\end{table*}

For the purposes of our power comparisons, each of the above instruction workloads are normalized to generate 10000 instructions.  Such a large instruction window is ideal to allow buffers to fill and behavioral characteristics to develop.  The specific values used for each workload are listed in Table ~\ref{tab:insprofile}.
\subsection{Model Implementation}
The following section details the model implementatations in our simulator.  The basic re-order buffer model we use as a base-line for comparison is a standard circular ROB model.  Section ~\ref{sec:circ} discusses its implementation.  We further model three optimizations for re-order buffers in an attempt to improve overall power usage: 1) Distributed (Cluster based) ROB, 2) Dynamically Sized ROB, 3) Reduced Output Port ROB (Retention Latch).  Each of these optimized models are built on top of the underlying circular ROB model to provide as close a behavioral and power comparison as possible.  Each of the optimizations, as well as the standard circular reorder buffer, are described in detail below.
\subsubsection{Circular ROB}
\label{sec:circ}
The circular ROB is the basic current implementation of the reorder buffer. It is implemented as a circular FIFO buffer, and the beginning and end of the used region are tracked by the head and tail pointers, respectively. When an instruction is issued, space is reserved for the instruction's result at the tail pointer, and the tail pointer is incremented. When the instruction completes, the result is inserted into the reorder buffer at the reserved space. The result is finally committed to the architecture register file when the head pointer passes through it; each cycle, results are committed from the head pointer and the head pointer is incremented repeatedly, until either an unfinished instruction result slot is reached or all write ports are used up.

The circular ROB is considered full when the tail pointer reaches the head pointer, as the head pointer denotes the start of the in-use region and no more space can be reserved from the tail pointer. Conversely, then buffer is empty when the head pointer catches up to the tail pointer, as every instruction in the buffer has now been committed to the ARF.

\subsubsection{Distributed (Cluster based) ROB}
Our distributed (cluster based) ROB is modeled similarly to the circular ROB.  Instead of having a single ROB buffer, 
numerous ROB buffers are instantiated.  In a real system, there would be one ROB buffer for each functional 
unit cluster.  However, since we do not model functional units in our simulator, we simply divide the ROB 
into multiple smaller ROBs.  Each of these ROBs implement the default circular ROB model.  Each ROB segment 
features a head pointer and a tail pointer and contains an equal portion of the total ROB space.  No further 
enhancements need to be made to the default circular ROB model as the inclusion of the central FIFO allows the 
ROB clusters to operate entirely independently of one another.  Each ROB might as well be the only ROB in the system. 

The largest modeling change required by the distributed ROB is the inclusion of the central FIFO queue.  This 
FIFO queue is responsible for maintaining a global state of order between instructions in the different ROB buffers. 
The FIFO queue is modeled as a modified circular buffer and each entry contains: 1) PC of instruction, 
2) ROB{\char'137}ID where the instruction placeholder resides, and 3) a valid bit corresponding to the completion state of 
the instruction.  The total number of entries in the FIFO queue is equal to the total entry size of the ROB.  
Each active entry in the FIFO queue correlates with an active entry in one of the ROB clusters.  

The distributed ROB requires only minor changes to the basic circular buffer to realize its effectiveness.  Instructions are 
read from the Instruction Queue as usual and inserted into their corresponding ROB entry while updating the corresponding tail 
pointer.  Since there are now multiple ROBs into which instructions can be inserted, a quick modulus is performed on the 
destination register of the instruction to divide the instructions equally between each ROB.  This presents the possibility 
for a worst-case situation where the entire instruction stream is blocked due to improper balancing between ROB clusters.  
This situation would occur very rarely in practice and would induce no form of deadlock or livelock in the system -- 
it would merely affect performance.  Possible avoidance techniques can be researched as future work.

At the same time as inserting the instruction from the IQ into the ROB cluster, an entry must be recorded in the central FIFO 
queue to maintain global program order.  At this point, both the instruction PC and the recently determined ROB{\char'137}ID are 
noted in the central FIFO queue.  The tail pointer of the central FIFO queue is increased accordingly to match.

Upon completion of an instruction, an instruction must be flagged as valid in both the ROB cluster in which it resides as well 
as its corresponding central FIFO queue entry.  The central FIFO queue then directs the appropriate ROB to write the instruction 
output to its write port when all prior instructions have been written so that program order is maintained.  This is the second 
major behavioral difference between the circular ROB and the distributed ROB, as writes and write-order is driven and determined by 
the central FIFO queue instead of the ROB cluster itself. 

\subsubsection{Dynamically Sized ROB}
The dynamically sized ROB is an optimization on the circular ROB where the buffer is divided into partitions, and those partitions deemed unnecessary are powered off to conserve energy. Our implementation of the basic dynamic ROB is behaviorally the same as that detailed in \cite{kucuk2}.

Downsizing the ROB is based on a periodic sampling of the buffer state. A number of cycles, {\it update\_period}, is defined, and every {\it update\_period} cycles the size of the ROB is updated. Every {\it sample\_period} cycles, the number of active entries is recorded, and the quantity {\it active\_size} is recorded as the average of these samples between each {\it update\_period}. The current maximum capacity of the reorder buffer is defined as the {\it current\_size}, and the size of a single ROB partition is defined as {\it partition\_size}. After each {\it update\_period} cycles, the ROB checks how full the buffer is, and if {\it current\_size} - {\it active\_size} > {\it partition\_size}, then a single partition is turned off.

Increasing the size of the ROB is dependent on how often the buffer fills up. A value, defined as the {\it overflow\_count} is incremented each cycle that instruction issue is stalled because the ROB is full. An {\it overflow\_threshold} is defined, and if during an {\it update\_period}, {\it overflow\_count} > {\it overflow\_threshold}, then a partition is turned on.

A conservative approach of deallocating strictly from one end of the buffer, and allocating strictly towards that end is followed. For example, if the ROB consisted of four partitions, downsizing the buffer would turn off the fourth, and then the third. At this point, if we were to increase the size of the buffer, the third partition would be turned on first, and the fourth partition next.

When the ROB's size is updated, partitions are not immediately turned off, since the partition could coincide with the active region of the buffer. If deallocating, this would disable a part of the active region, making instructions in the region impossible to complete. If allocating, this would insert an empty segment right into the middle of the FIFO queue, logically breaking the buffer. It is only safe to turn a partition off/on when the active region is not wrapped around (that is, the head pointer is less than the tail pointer), and the tail pointer comes before the first index into the partition to turn on/off. \cite{kucuk3} details a worst case scenario of deallocating, where the active region is wrapped (head is greater than tail), and both pointers lie in the region to be turned off. In this case, the head pointer must first clear the entries already in the buffer. Since the tail pointer is already in the partition, it will continue to write into the partition, and the head pointer must come around a second time to clear out these new entries. Only then can the partition be safely deallocated, after the head pointer has wrapped around to zero twice.

\subsubsection{Optimized Dynamic ROB}
We implement an optimized version of the dynamic ROB detailed in \cite{kucuk2} and \cite{kucuk3}, opting to be more aggressive with turning off partitions in order to save power, and to improve the partition allocation/deallocation scheme.

When downsizing the regular dynamic ROB, a single partition is turned off if {\it current\_size} - {\it active\_size} > {\it partition\_size}. In an effort to minimize the buffer size and thus the power consumed, we choose to downsize by

\begin{center}
$\lfloor \frac{current\_size - active\_size}{partition\_size} \rfloor$
\end{center}

Thus if much less than the capacity of the buffer is active, several partitions may be turned off at once.

To more efficiently resize the buffer, we found that choosing the first valid partition immediately after the one housing the tail pointer is optimal. For example, if we are allocating a partition in a four partition buffer, and the tail pointer resides in partition 3, we first check if partition 4 can be turned on, then partition 1, then partition 2.

In allocating the buffer, the reasoning is as follows. We aim to enable a disabled partition. It is impossible for the head pointer to lie in the disabled partition, thus there is no need to consider the head pointer. To maintain the logical consistency of the buffer, we cannot enable a partition that would divide the active region of the buffer. Thus, we must allocate a partition that comes after the tail pointer, and if we wish the buffer size to grow as soon as possible, the partition to be allocated must be the first disabled partition after the tail pointer.

In deallocating the buffer, turning off the first partition after the tail pointer is also optimal. Being after the tail pointer, once we mark the partition for disabling we can prevent the tail pointer from writing into it. This prevents the worst case scenario where the head pointer must wrap around 0 twice to disable a partition. The next enabled partition immediately after the tail pointer is also the one the active region will leave first (if the region is in the partition; if not the partition is already empty and ready to deactivate), thus it will empty out first. If we are to maximize the power savings, we must disable the first partition that is available to be disabled, thus the first active partition after the tail is the optimal choice.

One last optmization we implemented was just-in-time allocation of partitions. Normally, when the tail pointer increments, if a partition is not active the tail pointer simply skips it. In our optimization, before skipping the tail pointer will check if the disabled partition is marked to be enabled. If so, instead of skipping over it, the partition will be turned on and the tail pointer will write into it. This ensures that each partition to be turned on is enabled at the last possible moment, saving the energy that would otherwise be consumed by an empty partition waiting to be written into.

\subsubsection{Reduced Output Port ROB (Retention Latch)}


\subsection{Power Tabulation Implementation}
