\section{Project Implementation}
Our simulator provides a cycle accurate behavioral model of a standard circular re-order buffer.  At the outset of the project, the standard re-order buffer we intended to implement was a non-circular RAM-based re-order buffer.  However, after feedback from the course instructor and students it was decided that a circular buffer is more widely held as being the 'standard' buffer type and would serve as an ideal underlying model for power optimizations.  Thus, we implement and compare the standard circular re-order buffer to circular re-order buffers with the following optimizations: 1) Distributed (Cluster based) ROB, 2) Dynamically Sized ROB, 3) Reduced Output Port ROB (Retention Latch). The following sections outline each of the above model implementations as well as input instruction generation and power results tabulation.
\subsection{Instruction Generation}

\begin{table*}
\centering
\begin{tabular}{|c|c|c|c|} \hline
Instruction Type&Cycle Count&Instruction Type&Cycle Count\\ \hline
\texttt{LOAD}&20&\texttt{STORE}&20\\ \hline
\texttt{ADD}&1&\texttt{FADD}&3\\ \hline
\texttt{SUB}&1&\texttt{FSUB}&3\\ \hline
\texttt{MULT}&3&\texttt{FMULT}&5\\ \hline
\texttt{DIV}&18&\texttt{FDIV}&6\\ \hline\end{tabular}
\caption{Modeled instruction types and their corresponding completion cycle counts.}
\label{tab:instypetable}
\end{table*}

We model the input to our simulator as a stream of integer and floating point instructions.  The instructions are represented at the bit-level and model MIPS instructions as closely as possible.  Each instruction consists of 1) Instruction type, 2) Source and destination registers 3) a PC.  Table ~\ref{tab:instypetable} indicates the types of instructions modeled.  Each instruction type also has a predetermined cycle execution time designating the number of cycles that must elapse between instruction issue and the completion of the instruction.  As modeling functional units goes beyond the scope of this simulator, instructions are flagged as complete after the listed number of cycles has elapsed.  The actual cycle counts are the same as those modeled in MIT's Graphite many-core processor simulator\cite{graphite}, with the exception of LOAD and STORE.  The cycle counts corresponding to LOAD and STORE instructions are estimated as a predetermined 20 cycles each.  This is simply an estimation as the actual cycle count is heavily dependent on cache architecture and benchmark specific cache behavior.  Since both of these topics are beyond the scope of the simulator, we estimate the completion time of LOAD and STORE instructions as a set value substantially longer than the other more accurate instruction types.

Registers are generated in bit representation as 4 bits each totaling 12 bits for the s1, s2 and d registers in each instruction. Currently, our representation of instructions make no distinction between zero, 1, and 2 operand instructions.  All instructions regardless of type feature two operands.  This feature is supported by the fact that a memory hierarchy and functional units are not simulated by our system and as such immediate values have no direct use.  Further, every instruction features a d register regardless of type.  Because our simulator features operand forwarding from the ROB, it is necessary for the generation of registers to keep track of past destination registers to use as dependent operands in future instructions.  This history buffer is implemented as a rotating bit register from which prior destination registers can be indexed.

Each instruction also features a program counter associated with the instruction.  While this is clearly a simplification of a real system, it serves the purposes of our simulation as a uniquely identifiable tag by which to differentiate instructions.  In both a real system and our simulator, a statically set 32 bit value is used to represent this PC/tag.  As such, the specific values contained in the PC/tag will yield accurate transition results (nonexistent) and is thus are irrelevant.  Simply starting the PC of the first instruction in the stream at 0 and incrementing by 4 each instruction guarantees uniqueness among PCs and serves the purposes of an instruction tag.

The aforementioned instruction fields have multiple modes of generation.  Our simulator synthetically generates an instruction input trace based on a prescribed instruction profile.  The instruction profile features: 1) a percent rate of occurrence for each instruction type, 2) a rate corresponding to the interdependence of registers between instructions, and 3) an overall instruction count.

The instruction generator is currently capable of generating four distinct instruction streams corresponding to different instruction workloads.  The first instruction stream is marked as the default instruction stream.  It features equal percentages of each type of instruction as well as a 10\% register dependence rate.  This register dependence rate was selected arbitrarily to act as a starting point for modeling data dependencies between instructions.

The remaining three instruction streams are modeled after SPEC-FP benchmarks \cite{rupnow}.  The benchmarks were chosen to represent three major modes of operation:  floating point heavy execution, integer heavy execution, and mixed type execution.  For a floating point heavy execution, 173.applu was selected and modeled.  173.applu models parabolic/elliptical partial differential equations and features almost exclusively floating point operations as well as a large number of memory operations making it useful as both a floating point benchmark as well as a long running memory intensive benchmark.  191.fma3d is used to model integer heavy execution.  It models finite-element crash simulation and features very few floating point operations and substantially fewer memory operations than 173.applu making it an ideal light-weight integer workload.  Finally, 183.equake is used to represent the average workload.  It models seismic wave propagation and features both integer and floating point operations as well as moderate memory usage.  As such it acts as a more representative general workload than the original default workload.  Each of the SPEC-FP benchmarks feature a 6{\char'045} register forwarding frequency as is reported by \cite{kucuk}.

\begin{table*}
\centering
\begin{tabular}{|c|c|c|c|c|} \hline
ins{\char'137}profile&default{\char'137}profile&173{\char'056}applu&191{\char'056}fma3d&183{\char'056}equake\\ \hline
loadProc&0.10&0.32&0.12&0.37\\ \hline
storeProc&0.10&0.12&0.24&0.06\\ \hline
addProc&0.10&0.01&0.15&0.08\\ \hline
subProc&0.10&0.01&0.15&0.08\\ \hline
multProc&0.10&0.01&0.15&0.08\\ \hline
divProc&0.10&0.01&0.15&0.08\\ \hline
faddProc&0.10&0.13&0.01&0.07\\ \hline
fsubProc&0.10&0.13&0.01&0.06\\ \hline
fmultProc&0.10&0.13&0.01&0.06\\ \hline
fdivProc&0.10&0.13&0.01&0.06\\ \hline
forwardingRate&0.10&0.06&0.06&0.06\\ \hline
instCount&100000&100000&100000&100000\\ \hline\end{tabular}
\caption{Benchmark Instruction Profiles showing percent rate of occurrence of each instruction type.}
\label{tab:insprofile}
\end{table*}

For the purposes of our power comparisons, each of the above instruction workloads are normalized to generate 10000 instructions.  Such a large instruction window is ideal to allow buffers to fill and behavioral characteristics to develop.  The specific values used for each workload are listed in Table ~\ref{tab:insprofile}.
\subsection{Model Implementation}
The following section details the model implementations in our simulator.  The basic re-order buffer model we use as a base-line for comparison is a standard circular ROB model.  Section ~\ref{sec:circ} discusses its implementation.  We further model three optimizations for re-order buffers in an attempt to improve overall power usage: 1) Distributed (Cluster based) ROB, 2) Dynamically Sized ROB, 3) Reduced Output Port ROB (Retention Latch).  Each of these optimized models are built on top of the underlying circular ROB model to provide as close a behavioral and power comparison as possible.  Each of the optimizations, as well as the standard circular reorder buffer, are described in detail below.
\subsubsection{Circular ROB}
\label{sec:circ}
The circular ROB is the basic current implementation of the reorder buffer, so far each of the other ROB designs will use the 
circular array for each instruction entry.  Each instruction entry will have a flag to determine if its result is valid, a 
result field (currently 32 bits), the corresponding register id tag and the PC of the instructions.  There are two additional
fields in each entry that is an artifact of our simulation, the first of which is a flag to denote a floating point entry, and 
mark that the result of the next entry is a continuation of the current one.  The second element that is an artifact of the
simulator is the cycles counter, which acts as a timing simulator and will determine when the result will finally be produced
by the execution unit.  The ROB is simply an array of these entry structures, and two pointers (32 bits) that will point
to the head or tail of the circular FIFO buffer.  Also the variables used for power tabulation are a part of the structure as 
another artifact of our simulator.

The behavioral simulation is broken down into three main sections.  First is the update stage, which will cycle 
through each entry of the ROB, and decrement the cycles counter.  When it reaches zero, the valid flag is marked and the
result is stored into the result element of the entry.  Next is the ARF stage, where the top N entries are checked
for its valid flag (where N is the ways the processor is super scalar).  The entries are committed to the ARF if it is at 
the head of the buffer and its valid flag is set.
Lastly we simulate the interaction with the instruction queues.  Place holder spots are written at the tail of the buffer
at most N times. The place holder entry will unmark the valid flag (if it was previously set), and insert the pipeline cycle
time until execution completion. Also in this stage we check if operand forwarding is needed for any instructions that is 
requested by the IQ.  These three stages will repeat until the end of the instruction stream.

\subsubsection{Distributed (Cluster based) ROB}
Our distributed (cluster based) ROB is modeled similarly to the circular ROB.  Instead of having a single ROB buffer, numerous ROB buffers are instantiated.  In a real system, there would be one ROB buffer for each functional unit cluster.  However, since we do not model functional units in our simulator, we simply divide the ROB into multiple smaller ROBs.  Each of these ROBs implement the default circular ROB model.  Each ROB segment features a head pointer and a tail pointer and contains an equal portion of the total ROB space.  No further enhancements need to be made to the default circular ROB model as the inclusion of the central FIFO allows the ROB clusters to operate entirely independently of one another.  Each ROB might as well be the only ROB in the system.

The largest modeling change required by the distributed ROB is the inclusion of the central FIFO queue.  This FIFO queue is responsible for maintaining a global state of order between instructions in the different ROB buffers. The FIFO queue is modeled as a modified circular buffer and each entry contains: 1) PC of instruction, 2) ROB{\char'137}ID where the instruction placeholder resides, and 3) a valid bit corresponding to the completion state of the instruction.  The total number of entries in the FIFO queue is equal to the total entry size of the ROB.  Each active entry in the FIFO queue correlates with an active entry in one of the ROB clusters.

The distributed ROB requires only minor changes to the basic circular buffer to realize its effectiveness.  Instructions are read from the Instruction Queue as usual and inserted into their corresponding ROB entry while updating the corresponding tail pointer.  Since there are now multiple ROBs into which instructions can be inserted, a quick modulus is performed on the destination register of the instruction to divide the instructions equally between each ROB.  This presents the possibility for a worst-case situation where the entire instruction stream is blocked due to improper balancing between ROB clusters.  This situation would occur very rarely in practice and would induce no form of deadlock or livelock in the system -- it would merely affect performance.  Possible avoidance techniques can be researched as future work.

At the same time as inserting the instruction from the IQ into the ROB cluster, an entry must be recorded in the central FIFO queue to maintain global program order.  At this point, both the instruction PC and the recently determined ROB{\char'137}ID are noted in the central FIFO queue.  The tail pointer of the central FIFO queue is increased accordingly to match.

Upon completion of an instruction, an instruction must be flagged as valid in both the ROB cluster in which it resides as well as its corresponding central FIFO queue entry.  The central FIFO queue then directs the appropriate ROB to write the instruction output to its write port when all prior instructions have been written so that program order is maintained.  This is the second major behavioral difference between the circular ROB and the distributed ROB, as writes and write-order is driven and determined by the central FIFO queue instead of the ROB cluster itself.

\subsubsection{Dynamically Sized ROB}
Our implementation of the basic dynamic ROB is behaviorally the same as that detailed in \cite{kucuk2} and the background section.

For {\it P} partitions, instead of allocating one region of memory as in the circular ROB we allocate {\it P} regions, and associate with each region two status bits, denote the four states a ROB partition can have: {\tt ENABLED}, {\tt DISABLED}, {\tt TO\_ENABLE}, and {\tt TO\_DISABLE}. Also, where pointer incrementation in the circular buffer was done as:

\begin{center}
$ new\_ptr = (old\_ptr + 1) \: \% \: ROB\_size $
\end{center}

Which is no long accurate in the dynamic ROB. The pointer incrementation module for the dynamic ROB was updated to check if the incremented pointer is stepping into a new partition, and to step over that partition if necessary. When incrementing the head pointer, only partitions labeled {\tt ENABLED} and {\tt TO\_DISABLE} are valid. When incrementing the tail pointer, only partitions labeled {\tt ENABLED} are valid.

The entry fetch module also requires updating. Whereas in the circular buffer, an entry is located simply by taking the head or tail pointer as the offset into the buffer, the dynamic buffer must now map the pointer to a particular partition and an offset into that partition.

At cycle completion, a module was added to perform sampling and resizing. Every cycle, the module checks for a stall due to the buffer being full, and if so the {\it overflow\_count} is incremented. Every {\it sample\_period} cycles, the buffer's {\it active\_size} is sampled. Every {\it update\_period}, the buffer's size is updated by marking the appropriate partitions {\tt TO\_ENABLE} or {\tt TO\_DISABLE}. Each cycle, the head and tail pointers are checked against the marked partitions to see if their state can be updated to {\tt ENABLED} or {\tt DISABLED}.

\cite{kucuk3} takes a conservative approach of deallocating strictly from one end of the buffer, and also allocating strictly towards that end. For example, if the ROB consisted of four partitions, downsizing the buffer would turn off the fourth, and then the third. At this point, if we were to increase the size of the buffer, the third partition would be turned on first, and the fourth partition next.

When the ROB's size is updated, partitions are not immediately turned off, since the partition could coincide with the active region of the buffer. If deallocating, this would disable a part of the active region, making instructions in the region impossible to complete. If allocating, this would insert an empty segment right into the middle of the FIFO queue, logically breaking the buffer. It is only safe to turn a partition off/on when the active region is not wrapped around (that is, the head pointer is less than the tail pointer), and the tail pointer comes before the first index into the partition to turn on/off. \cite{kucuk3} details a worst case scenario of deallocating, where the active region is wrapped (head is greater than tail), and both pointers lie in the region to be turned off. In this case, the head pointer must first clear the entries already in the buffer. Since the tail pointer is already in the partition, it will continue to write into the partition, and the head pointer must come around a second time to clear out these new entries. Only then can the partition be safely deallocated, after the head pointer has wrapped around to zero twice.

\subsubsection{Optimized Dynamic ROB}
We implement an optimized version of the dynamic ROB detailed in \cite{kucuk2} and \cite{kucuk3}, opting to be more aggressive with turning off partitions in order to save power, and to improve the partition allocation/deallocation scheme.

When downsizing the regular dynamic ROB, a single partition is turned off if {\it current\_size} - {\it active\_size} > {\it partition\_size}. In an effort to minimize the buffer size and thus the power consumed, we choose to downsize by

\begin{center}
$\lfloor \frac{current\_size - active\_size}{partition\_size} \rfloor$
\end{center}

Thus if much less than the capacity of the buffer is active, several partitions may be turned off at once.

To more efficiently resize the buffer, we found that choosing the first valid partition immediately after the one housing the tail pointer is optimal. For example, if we are allocating a partition in a four partition buffer, and the tail pointer resides in partition 3, we first check if partition 4 can be turned on, then partition 1, then partition 2.

In allocating the buffer, the reasoning is as follows. We aim to enable a disabled partition. It is impossible for the head pointer to lie in the disabled partition, thus there is no need to consider the head pointer. To maintain the logical consistency of the buffer, we cannot enable a partition that would divide the active region of the buffer. Thus, we must allocate a partition that comes after the tail pointer, and if we wish the buffer size to grow as soon as possible, the partition to be allocated must be the first disabled partition after the tail pointer.

In deallocating the buffer, turning off the first partition after the tail pointer is also optimal. Being after the tail pointer, once we mark the partition for disabling we can prevent the tail pointer from writing into it. This prevents the worst case scenario where the head pointer must wrap around 0 twice to disable a partition. The next enabled partition immediately after the tail pointer is also the one the active region will leave first (if the region is in the partition; if not the partition is already empty and ready to deactivate), thus it will empty out first. If we are to maximize the power savings, we must disable the first partition that is available to be disabled, thus the first active partition after the tail is the optimal choice.

One last optimization we implemented was just-in-time allocation of partitions. Normally, when the tail pointer increments, if a partition is not active the tail pointer simply skips it. In our optimization, before skipping the tail pointer will check if the disabled partition is marked to be enabled. If so, instead of skipping over it, the partition will be turned on and the tail pointer will write into it. This ensures that each partition to be turned on is enabled at the last possible moment, saving the energy that would otherwise be consumed by an empty partition waiting to be written into.

\begin{table*}[!tb]
\centering
\caption{FP Heavy Instruction Profile Results(B1)}
\begin{tabular}{|c|c|c|c|c|c|} \hline
    & Circular  & Distrubuted & Dynamic & Dynamic (optimized) & OOP\\ \hline
Cycles&82,722	&50,541&    	84,211	&84,078&        	82,153\\ \hline
Bit Cycles&1,483,701,792&	1,399,581,372&	1,453,144,453	&1,470,555,825	&1,522,130,784\\ \hline
Trans. to High&1,967,483&	1,719,957	&1,942,948	&1,930,476	&3,235,293\\ \hline
Reg Comp&6,725,088&	6,631,913&	6,710,777&	6,718,043	&11,160,291\\ \hline
\end{tabular}
\label{tab:bench1}
\end{table*}

\begin{table*}[!tb]
\centering
\caption{int Heavy Instruction Profile Results(B2)}
\begin{tabular}{|c|c|c|c|c|c|} \hline
    & Circular  & Distrubuted & Dynamic & Dynamic (optimized) & OOP\\ \hline
Cycles&25,781&	25,794&	26,079	&25,783	&25,780\\ \hline
Bit Cycles&462,408,016	&714,287,448	&310,408,263	&317,109,601	&477,651,840\\ \hline
Trans. to High&1,347,679&	1,134,479	&1,363,418&	1,369,396	&2,262,036\\ \hline
Reg Comp&3,220,687	&3,221,904	&3,219,866	&3,221,335&	5,155,838\\ \hline
\end{tabular}
\label{tab:bench2}
\end{table*}

\begin{table*}[!tb]
\centering
\caption{Mix Instruction Profile Results(B3)}
\begin{tabular}{|c|c|c|c|c|c|} \hline
    & Circular  & Distrubuted & Dynamic & Dynamic (optimized) & OOP\\ \hline
Cycles&29,858	&29,914	&31,733	&30,509	&29,845\\ \hline

Bit Cycles&535,533,088&	828,378,488&	352,433,432	&342,715,483	&552,968,160\\ \hline

Trans. to High&4,591,862	&4,585,663	&4,588,186&	4,603,780&	6,758,124\\ \hline

Reg Comp&1,688,252&	1,436,544	&1,655,666	&1,657,563	&2,802,135\\ \hline
\end{tabular}
\label{tab:bench3}
\end{table*}


\subsubsection{Omitted Output Port ROB (Retention Latch)}
The main difference between the Circular ROB and the Omitted Output Port (OOP) ROB is that the OOP adds in a retention latches and is not allowed to forward any results directly to DU.  This our implementation of the OOP ROB simply extends the circular ROB, adding in a structure for the retention latches.  The latches is modeled very similar to the ROB entries, an array
of a latch entry structure.  Each latch entry contains a 32 bit value for the results to be stored as well small tag to the corresponding destination register of the result.  As an artifact of our simulation a flag to denote that the entry is part of a floating point operation is required as well.  Also an additional counter was added to count the additional re-forwarding when a value is committed to the ARF but also needs to be forwarded to the DU unit as well.  Though this is not an increasing number of ports driven, it may affect future power calculations relating to capacitance.  Lastly as changing the semantic of the number of forwards to the DU, the count refers to the number time the entry is read from a retention latch.

As a few minor changes to the behavioral function of the OOP ROB, the first of which is the lack of the ability to forward operands.  Thus in the simulated stage of reading from the instruction stream, when we would normally check if the operand is in the ROB and forward.  We instead do the following, we still check to see if the operand is in the ROB, and the retention latches. If the entry is not in the ROB, or the latches, the operand would be available in the ARF or memory, in the converse case,  the entry in both, the ROB, and the latches, the operand is forwarded from the latches and the counter is incremented .  In the case that the entry exists in the ROB, but not in the latches, a flag would be set in the ROB to forward the result when committing to the ARF. The last case, that is the entry exists in the latches and not in the ROB, means that the result has already been committed and the result could be forwarded from the ARF.  Next in our update entries (when the cycle counter expires -- execution has completed) we would add in the new entry to the retention latch.  Lastly when the ROB entires are valid, and ready to be committed to the ARF,
if the forwarding flag is set, the forwarding counter is incremented.

\subsection{Power Tabulation Implementation}
In order for our simulation to determine the power utilization, we do not try and equate each event with an associated cost in joules.  As technology changes, and new techniques are developed to decease circuit level power usages, our simulation will become less and less accurate.  Instead we chose to simply tabulate each event that is associated with power cost, such as bit flips from 0 to 1, register comparator usage, and bit lines driven.  To help measure leakage power and overall states of the ROB, we also keep track of the time (in cycles) each bit stays in the high state, or the low state.

At the start of each cycle the simulator take a snapshot of the entire ROB, this includes each ROB entry, head/tail pointers (circular ROB), forward flags (OOP ROB), and etc as the type of ROB changes.  Then at the end of each cycle completion, we are able to compare which bits have changed, from low to high or high to low.   This results of the comparisons are tabulated
and printed out at the of the simulation runs.  The checkpoint comparison allows the simulator to easily modularize power data collection for any type of ROB.

The events that cannot be captured by the checkpoint comparison, is captured during the behavioral simulation.  These items are stateless such as comparators used, bit lines driven, and etc.
As part of the behavioral simulation, the respective counters would simply be incremented as part of simulating the usage of the item.

These final tabulations allow the user to fairly comparing the type and algorithm of the reorder buffer with our worrying about the circuit level technology underneath.





























